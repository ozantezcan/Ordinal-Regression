{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./dataset/regression\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/regression/bank32nh.data\", sep=' ', header=None)\n",
    "train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "print(train_df.shape)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['label_ord']=train_df['label']\n",
    "label=train_df.label.values\n",
    "sorted_idx=np.argsort(train_df.label.values)\n",
    "num_samples_per_class=train_df.shape[0]/num_classes\n",
    "print(num_samples_per_class)\n",
    "\n",
    "bins=[(k*1e-4+label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]]) for k in range(1,num_classes+1)]\n",
    "bins.insert(0,0.0)\n",
    "bins[-1]=bins[-1]+1\n",
    "print(bins)\n",
    "\n",
    "label_ord=label.copy()\n",
    "for k in range(num_classes):\n",
    "    print(np.all([label>=bins[k], label<bins[k+1]],0))\n",
    "    label_ord[np.all([label>=bins[k], label<bins[k+1]],0)]=k\n",
    "    \n",
    "print(label_ord)\n",
    "\n",
    "\n",
    "train_df['label_ord']=label_ord\n",
    "print(train_df.head())\n",
    "\n",
    "plt.scatter(label,label_ord)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), label[sorted_idx],s=3,c=np.sort(label_ord[sorted_idx]))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ulimit = np.percentile(train_df.label.values, 98)\n",
    "llimit = np.percentile(train_df.label.values, 2)\n",
    "train_df['label'].ix[train_df['label']>ulimit] = ulimit\n",
    "train_df['label'].ix[train_df['label']<llimit] = llimit'''\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.label.values, bins=50, kde=False)\n",
    "plt.xlabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=train_df.values[:,:-2]\n",
    "\n",
    "#Normalize the features\n",
    "\n",
    "feat_max = np.amax(feat,axis=0)\n",
    "feat_min = np.amin(feat,axis=0)\n",
    "\n",
    "feat=(feat-feat_min)/(feat_max-feat_min)\n",
    "feat=feat*2-1\n",
    "\n",
    "'''feat_mean = np.mean(feat,axis=0)\n",
    "feat_std = np.std(feat,axis=0)\n",
    "\n",
    "feat=(feat-feat_mean)/feat_std\n",
    "'''\n",
    "label_ord=train_df.values[:,-1].astype(np.int)\n",
    "\n",
    "print(np.mean(feat,axis=0))\n",
    "print(np.min(feat,axis=0))\n",
    "print(feat.shape)\n",
    "print(label_ord)\n",
    "\n",
    "fvec=feat.copy()\n",
    "#label=np.eye(num_classes)[label_ord]\n",
    "#print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1000\n",
    "\n",
    "test_idx=sorted_idx[np.floor(np.linspace(0,len(label_ord)-1,test_size)).astype(np.int)]\n",
    "train_idx = np.setdiff1d(np.arange(0,len(label_ord)),test_idx)\n",
    "\n",
    "\n",
    "\n",
    "label_ord_test=label_ord[test_idx]\n",
    "label_ord_train=label_ord[train_idx]\n",
    "#label_test=np.eye(num_classes)[label_ord_test]\n",
    "#label_train=np.eye(num_classes)[label_ord_train]\n",
    "fvec_test=fvec[test_idx,:]\n",
    "fvec_train=fvec[train_idx,:]\n",
    "\n",
    "print(label_ord_test.shape)\n",
    "print(label_ord_train.shape)\n",
    "print(fvec_test.shape)\n",
    "print(fvec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.Ridge(alpha = .5)\n",
    "\n",
    "# Train the model using training sets\n",
    "regr.fit(fvec_train, label_ord_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "label_ord_pred = np.round(regr.predict(fvec_test)).astype(np.int)\n",
    "label_ord_pred[label_ord_pred<0]=0\n",
    "label_ord_pred[label_ord_pred>=num_classes]=num_classes-1\n",
    "\n",
    "label_ord_tr_pred = np.round(regr.predict(fvec_train)).astype(np.int)\n",
    "label_ord_tr_pred[label_ord_tr_pred<0]=0\n",
    "label_ord_tr_pred[label_ord_tr_pred>=num_classes]=num_classes-1\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print('Training')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_tr_pred, label_ord_train))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_tr_pred==label_ord_train))\n",
    "\n",
    "# The mean squared error\n",
    "print('Validation')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_pred, label_ord_test))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_pred==label_ord_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "\n",
    "clf.fit(fvec_train, label_ord_train)\n",
    "label_ord_pred = clf.predict(fvec_test)\n",
    "label_ord_tr_pred = clf.predict(fvec_train)\n",
    "print(np.histogram(label_ord_pred))\n",
    "print(np.histogram(label_ord_test))\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "\n",
    "# The mean squared error\n",
    "print('Training')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_tr_pred, label_ord_train))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_tr_pred==label_ord_train))\n",
    "\n",
    "# The mean squared error\n",
    "print('Validation')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_pred, label_ord_test))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_pred==label_ord_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "label_test=np.eye(num_classes)[label_ord_test]\n",
    "label_train=np.eye(num_classes)[label_ord_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp(x, hidden_sizes, activation_fn=tf.nn.relu,dropout_rate=.5,std_dev=1.0):\n",
    "    if not isinstance(hidden_sizes, (list, tuple)):\n",
    "        raise ValueError(\"hidden_sizes must be a list or a tuple\")\n",
    "        \n",
    "    scope_args = {'initializer': tf.random_normal_initializer(stddev=std_dev)}\n",
    "    \n",
    "    for k in range(len(hidden_sizes)-1):\n",
    "        layer_name=\"weights\"+str(k)\n",
    "        #FC layers\n",
    "        with tf.variable_scope(layer_name, **scope_args):\n",
    "            W = tf.get_variable('W', shape=[x.shape[-1], hidden_sizes[k]])\n",
    "            b = tf.get_variable('b', shape=[hidden_sizes[k]])\n",
    "            x = activation_fn(tf.matmul(x, W) + b)\n",
    "            #Dropout before the last layer\n",
    "            x = tf.nn.dropout(x, keep_prob=dropout_rate)\n",
    "    #Softmax layer\n",
    "    with tf.variable_scope('outlayer', **scope_args):\n",
    "        W = tf.get_variable('W', shape=[x.shape[-1], hidden_sizes[-1]])\n",
    "        b = tf.get_variable('b', shape=[hidden_sizes[-1]])\n",
    "        return tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''fvec_n=fvec/np.round(np.max(label))\n",
    "label_n = label/np.round(np.max(label))'''\n",
    "def test_classification(model_function, learning_rate=0.1,num_iter=30000,num_log=2000):\n",
    "\n",
    "    with tf.Graph().as_default() as g:\n",
    "        # where are you going to allocate memory and perform computations\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            \n",
    "            # define model \"input placeholders\", i.e. variables that are\n",
    "            # going to be substituted with input data on train/test time\n",
    "            x_ = tf.placeholder(tf.float32, [None, fvec.shape[1]])\n",
    "            y_ = tf.placeholder(tf.float32, [None, num_classes])\n",
    "            y_logits = model_function(x_)\n",
    "            \n",
    "\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_logits))\n",
    "            '''train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)'''\n",
    "            train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "           \n",
    "            y_pred = tf.argmax(y_logits, 1)\n",
    "            y_true = tf.argmax(y_,1)\n",
    "            correct_prediction = tf.equal(y_pred, y_true)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            mae_error = tf.reduce_mean(tf.cast(tf.abs(y_pred-y_true), tf.float32))\n",
    "\n",
    "    with g.as_default(), tf.Session() as sess:\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # train\n",
    "        ids=[i for i in range(128)]\n",
    "        for iter_i in range(num_iter+1):\n",
    "            batch_xs = fvec_train[ids,:] \n",
    "            batch_ys = label_train[ids]\n",
    "            ids=[(ids[0]+100+i)%label_train.shape[0] for i in range(100)]\n",
    "            sess.run(train_step, feed_dict={x_: batch_xs, y_: batch_ys})\n",
    "            \n",
    "            # test trained model\n",
    "            if iter_i % num_log == 0:\n",
    "                tf_feed_dict = {x_: fvec_train, y_: label_train}\n",
    "                loss_tr, acc_tr, mae_tr, y_pred_tr,y_true_tr= sess.run(\n",
    "                    [loss, accuracy, mae_error, y_pred,y_true], feed_dict=tf_feed_dict)\n",
    "                tf_feed_dict = {x_: fvec_test, y_: label_test}\n",
    "                loss_val, acc_val, mae_val, y_pred_val,y_true_val= sess.run(\n",
    "                    [loss, accuracy, mae_error, y_pred,y_true], feed_dict=tf_feed_dict)\n",
    "                print('iteration %d\\t Training: loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t, Validation: loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t'%\n",
    "                      (iter_i, loss_tr, mae_tr, acc_tr, loss_val, mae_val, acc_val))\n",
    "                '''loss_val= sess.run(loss, feed_dict=tf_feed_dict)\n",
    "                print('iteration %d\\t loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t'%\n",
    "                      (iter_i, loss_val, loss_val, loss_val))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 16, 12, 12, 8, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=100000,num_log=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=500000,num_log=10000)\n",
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-4,num_iter=500000,num_log=10000)\n",
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=500000,num_log=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=1000000,num_log=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=5e-4,num_iter=300000,num_log=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
