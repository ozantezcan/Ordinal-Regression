{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank32nh.data\n",
      "bank8FM.data\n",
      "bostonhousing\n",
      "cal_housing.data\n",
      "cpu_act.data\n",
      "cpu_small.data\n",
      "house_16H.data\n",
      "house_8L.data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./dataset/regression\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8192, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./dataset/regression/bank32nh.data\", sep=' ', header=None)\n",
    "train_df=train_df.drop(train_df.columns[-1],axis=1)\n",
    "print(train_df.shape)\n",
    "\n",
    "columns=[\"feat\"+str(k) for k in range(train_df.shape[1])]\n",
    "columns[-1]=\"label\"\n",
    "train_df.columns=columns\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "      <th>feat17</th>\n",
       "      <th>feat18</th>\n",
       "      <th>feat19</th>\n",
       "      <th>feat20</th>\n",
       "      <th>feat21</th>\n",
       "      <th>feat22</th>\n",
       "      <th>feat23</th>\n",
       "      <th>feat24</th>\n",
       "      <th>feat25</th>\n",
       "      <th>feat26</th>\n",
       "      <th>feat27</th>\n",
       "      <th>feat28</th>\n",
       "      <th>feat29</th>\n",
       "      <th>feat30</th>\n",
       "      <th>feat31</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.413010</td>\n",
       "      <td>0.607442</td>\n",
       "      <td>0.332608</td>\n",
       "      <td>0.406812</td>\n",
       "      <td>-0.151224</td>\n",
       "      <td>1.525222</td>\n",
       "      <td>-0.144368</td>\n",
       "      <td>0.852368</td>\n",
       "      <td>0.412397</td>\n",
       "      <td>1.728169</td>\n",
       "      <td>-0.449231</td>\n",
       "      <td>4.078482</td>\n",
       "      <td>0.232042</td>\n",
       "      <td>-0.323190</td>\n",
       "      <td>0.792235</td>\n",
       "      <td>0.421474</td>\n",
       "      <td>-0.307503</td>\n",
       "      <td>3.086689</td>\n",
       "      <td>0.363949</td>\n",
       "      <td>0.441308</td>\n",
       "      <td>-0.276851</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.974706</td>\n",
       "      <td>-0.776759</td>\n",
       "      <td>-0.783770</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.603486</td>\n",
       "      <td>-0.997118</td>\n",
       "      <td>-0.502138</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.169388</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.602384</td>\n",
       "      <td>0.350618</td>\n",
       "      <td>0.429196</td>\n",
       "      <td>0.414476</td>\n",
       "      <td>-0.124489</td>\n",
       "      <td>4.597991</td>\n",
       "      <td>0.579458</td>\n",
       "      <td>0.651134</td>\n",
       "      <td>0.104394</td>\n",
       "      <td>0.636356</td>\n",
       "      <td>-0.283787</td>\n",
       "      <td>3.546643</td>\n",
       "      <td>0.115860</td>\n",
       "      <td>0.409074</td>\n",
       "      <td>2.152997</td>\n",
       "      <td>0.758680</td>\n",
       "      <td>0.341127</td>\n",
       "      <td>1.478951</td>\n",
       "      <td>0.662488</td>\n",
       "      <td>0.462398</td>\n",
       "      <td>0.339673</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.798979</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>-0.080542</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.125542</td>\n",
       "      <td>-0.983397</td>\n",
       "      <td>-0.107632</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.186039</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.242579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.322881</td>\n",
       "      <td>-0.538491</td>\n",
       "      <td>1.602260</td>\n",
       "      <td>0.039605</td>\n",
       "      <td>0.196023</td>\n",
       "      <td>1.909005</td>\n",
       "      <td>-0.675672</td>\n",
       "      <td>0.963618</td>\n",
       "      <td>0.147458</td>\n",
       "      <td>1.414008</td>\n",
       "      <td>0.495453</td>\n",
       "      <td>0.056459</td>\n",
       "      <td>-0.163151</td>\n",
       "      <td>0.350221</td>\n",
       "      <td>1.124090</td>\n",
       "      <td>1.398160</td>\n",
       "      <td>-0.456921</td>\n",
       "      <td>1.600723</td>\n",
       "      <td>0.650252</td>\n",
       "      <td>-0.247380</td>\n",
       "      <td>0.318002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.577355</td>\n",
       "      <td>-0.952645</td>\n",
       "      <td>-0.571600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.280392</td>\n",
       "      <td>0.771129</td>\n",
       "      <td>-0.665756</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.024203</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.233570</td>\n",
       "      <td>-0.936451</td>\n",
       "      <td>1.710192</td>\n",
       "      <td>2.179527</td>\n",
       "      <td>0.438461</td>\n",
       "      <td>4.742055</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.923273</td>\n",
       "      <td>0.597622</td>\n",
       "      <td>0.118409</td>\n",
       "      <td>0.229981</td>\n",
       "      <td>3.209085</td>\n",
       "      <td>-0.165046</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>1.335824</td>\n",
       "      <td>0.119910</td>\n",
       "      <td>13.070052</td>\n",
       "      <td>0.308221</td>\n",
       "      <td>-0.743841</td>\n",
       "      <td>0.258362</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.760084</td>\n",
       "      <td>-0.198235</td>\n",
       "      <td>-0.205276</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.509727</td>\n",
       "      <td>-0.579544</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.568492</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.469045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.403126</td>\n",
       "      <td>0.313367</td>\n",
       "      <td>0.822382</td>\n",
       "      <td>1.393975</td>\n",
       "      <td>0.253435</td>\n",
       "      <td>9.398630</td>\n",
       "      <td>0.312528</td>\n",
       "      <td>0.288321</td>\n",
       "      <td>0.431867</td>\n",
       "      <td>0.110369</td>\n",
       "      <td>0.294665</td>\n",
       "      <td>1.274100</td>\n",
       "      <td>0.328350</td>\n",
       "      <td>-0.288962</td>\n",
       "      <td>0.067075</td>\n",
       "      <td>0.632938</td>\n",
       "      <td>0.148618</td>\n",
       "      <td>3.633846</td>\n",
       "      <td>0.233204</td>\n",
       "      <td>-0.685285</td>\n",
       "      <td>-0.758206</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.170067</td>\n",
       "      <td>0.573352</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.622033</td>\n",
       "      <td>-0.134747</td>\n",
       "      <td>0.669948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.295913</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feat0     feat1     feat2     feat3     feat4     feat5     feat6  \\\n",
       "0  0.413010  0.607442  0.332608  0.406812 -0.151224  1.525222 -0.144368   \n",
       "1 -0.602384  0.350618  0.429196  0.414476 -0.124489  4.597991  0.579458   \n",
       "2 -0.322881 -0.538491  1.602260  0.039605  0.196023  1.909005 -0.675672   \n",
       "3 -0.233570 -0.936451  1.710192  2.179527  0.438461  4.742055 -0.163625   \n",
       "4  0.403126  0.313367  0.822382  1.393975  0.253435  9.398630  0.312528   \n",
       "\n",
       "      feat7     feat8     feat9    feat10    feat11    feat12    feat13  \\\n",
       "0  0.852368  0.412397  1.728169 -0.449231  4.078482  0.232042 -0.323190   \n",
       "1  0.651134  0.104394  0.636356 -0.283787  3.546643  0.115860  0.409074   \n",
       "2  0.963618  0.147458  1.414008  0.495453  0.056459 -0.163151  0.350221   \n",
       "3 -0.923273  0.597622  0.118409  0.229981  3.209085 -0.165046  0.012872   \n",
       "4  0.288321  0.431867  0.110369  0.294665  1.274100  0.328350 -0.288962   \n",
       "\n",
       "     feat14    feat15    feat16     feat17    feat18    feat19    feat20  \\\n",
       "0  0.792235  0.421474 -0.307503   3.086689  0.363949  0.441308 -0.276851   \n",
       "1  2.152997  0.758680  0.341127   1.478951  0.662488  0.462398  0.339673   \n",
       "2  1.124090  1.398160 -0.456921   1.600723  0.650252 -0.247380  0.318002   \n",
       "3  0.398148  1.335824  0.119910  13.070052  0.308221 -0.743841  0.258362   \n",
       "4  0.067075  0.632938  0.148618   3.633846  0.233204 -0.685285 -0.758206   \n",
       "\n",
       "   feat21    feat22    feat23    feat24  feat25    feat26    feat27    feat28  \\\n",
       "0     2.0  1.974706 -0.776759 -0.783770     8.0  0.603486 -0.997118 -0.502138   \n",
       "1     6.0  0.798979 -0.002820 -0.080542     2.0  1.125542 -0.983397 -0.107632   \n",
       "2     3.0  0.577355 -0.952645 -0.571600     5.0  1.280392  0.771129 -0.665756   \n",
       "3     4.0  0.760084 -0.198235 -0.205276     2.0  0.509727 -0.579544  0.480094   \n",
       "4     6.0  1.170067  0.573352  0.315217     2.0  0.622033 -0.134747  0.669948   \n",
       "\n",
       "   feat29    feat30  feat31     label  \n",
       "0     5.0  1.169388     9.0  0.049118  \n",
       "1     5.0  1.186039     7.0  0.242579  \n",
       "2     5.0  1.024203     6.0  0.000000  \n",
       "3     6.0  1.568492     7.0  0.469045  \n",
       "4     3.0  1.295913     9.0  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638.4\n",
      "[0.0, 0.0001, 0.012395000000000002, 0.051264999999999998, 0.15377600000000002, 1.8201649999999998]\n",
      "[False False  True ..., False False False]\n",
      "[False False False ...,  True False False]\n",
      "[ True False False ..., False  True False]\n",
      "[False False False ..., False False  True]\n",
      "[False  True False ..., False False False]\n",
      "[ 2.  4.  0. ...,  1.  2.  3.]\n",
      "      feat0     feat1     feat2     feat3     feat4     feat5     feat6  \\\n",
      "0  0.413010  0.607442  0.332608  0.406812 -0.151224  1.525222 -0.144368   \n",
      "1 -0.602384  0.350618  0.429196  0.414476 -0.124489  4.597991  0.579458   \n",
      "2 -0.322881 -0.538491  1.602260  0.039605  0.196023  1.909005 -0.675672   \n",
      "3 -0.233570 -0.936451  1.710192  2.179527  0.438461  4.742055 -0.163625   \n",
      "4  0.403126  0.313367  0.822382  1.393975  0.253435  9.398630  0.312528   \n",
      "\n",
      "      feat7     feat8     feat9    feat10    feat11    feat12    feat13  \\\n",
      "0  0.852368  0.412397  1.728169 -0.449231  4.078482  0.232042 -0.323190   \n",
      "1  0.651134  0.104394  0.636356 -0.283787  3.546643  0.115860  0.409074   \n",
      "2  0.963618  0.147458  1.414008  0.495453  0.056459 -0.163151  0.350221   \n",
      "3 -0.923273  0.597622  0.118409  0.229981  3.209085 -0.165046  0.012872   \n",
      "4  0.288321  0.431867  0.110369  0.294665  1.274100  0.328350 -0.288962   \n",
      "\n",
      "     feat14    feat15    feat16     feat17    feat18    feat19    feat20  \\\n",
      "0  0.792235  0.421474 -0.307503   3.086689  0.363949  0.441308 -0.276851   \n",
      "1  2.152997  0.758680  0.341127   1.478951  0.662488  0.462398  0.339673   \n",
      "2  1.124090  1.398160 -0.456921   1.600723  0.650252 -0.247380  0.318002   \n",
      "3  0.398148  1.335824  0.119910  13.070052  0.308221 -0.743841  0.258362   \n",
      "4  0.067075  0.632938  0.148618   3.633846  0.233204 -0.685285 -0.758206   \n",
      "\n",
      "   feat21    feat22    feat23    feat24  feat25    feat26    feat27    feat28  \\\n",
      "0     2.0  1.974706 -0.776759 -0.783770     8.0  0.603486 -0.997118 -0.502138   \n",
      "1     6.0  0.798979 -0.002820 -0.080542     2.0  1.125542 -0.983397 -0.107632   \n",
      "2     3.0  0.577355 -0.952645 -0.571600     5.0  1.280392  0.771129 -0.665756   \n",
      "3     4.0  0.760084 -0.198235 -0.205276     2.0  0.509727 -0.579544  0.480094   \n",
      "4     6.0  1.170067  0.573352  0.315217     2.0  0.622033 -0.134747  0.669948   \n",
      "\n",
      "   feat29    feat30  feat31     label  label_ord  \n",
      "0     5.0  1.169388     9.0  0.049118        2.0  \n",
      "1     5.0  1.186039     7.0  0.242579        4.0  \n",
      "2     5.0  1.024203     6.0  0.000000        0.0  \n",
      "3     6.0  1.568492     7.0  0.469045        4.0  \n",
      "4     3.0  1.295913     9.0  0.000000        0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD3CAYAAAAALt/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB2haAn0eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e746400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_df['label_ord']=train_df['label']\n",
    "label=train_df.label.values\n",
    "sorted_idx=np.argsort(train_df.label.values)\n",
    "num_samples_per_class=train_df.shape[0]/num_classes\n",
    "print(num_samples_per_class)\n",
    "\n",
    "bins=[(k*1e-4+label[sorted_idx[np.round(k*num_samples_per_class-1).astype(np.int)]]) for k in range(1,num_classes+1)]\n",
    "bins.insert(0,0.0)\n",
    "bins[-1]=bins[-1]+1\n",
    "print(bins)\n",
    "\n",
    "label_ord=label.copy()\n",
    "for k in range(num_classes):\n",
    "    print(np.all([label>=bins[k], label<bins[k+1]],0))\n",
    "    label_ord[np.all([label>=bins[k], label<bins[k+1]],0)]=k\n",
    "    \n",
    "print(label_ord)\n",
    "\n",
    "\n",
    "train_df['label_ord']=label_ord\n",
    "print(train_df.head())\n",
    "\n",
    "plt.scatter(label,label_ord)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a1d6bf390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFyCAYAAADccVJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1425f518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), label[sorted_idx],s=3,c=np.sort(label_ord[sorted_idx]))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a1d6b60b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHfCAYAAACiUkX2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5bRGxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d622a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''ulimit = np.percentile(train_df.label.values, 98)\n",
    "llimit = np.percentile(train_df.label.values, 2)\n",
    "train_df['label'].ix[train_df['label']>ulimit] = ulimit\n",
    "train_df['label'].ix[train_df['label']<llimit] = llimit'''\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.label.values, bins=50, kde=False)\n",
    "plt.xlabel('label', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.46686086e-03  -9.20904637e-04  -8.03606985e-01  -7.73078363e-01\n",
      "  -3.56635604e-03  -7.72843486e-01  -1.18393606e-04  -9.97569510e-04\n",
      "  -7.48644283e-01  -8.52985102e-01  -2.84872124e-03  -7.72901335e-01\n",
      "  -6.64816878e-03  -1.01483779e-03  -7.10571434e-01  -7.82965571e-01\n",
      "  -5.51937200e-03  -8.13909000e-01   6.02760301e-03   6.02673678e-03\n",
      "   1.52910570e-03  -3.44319661e-01  -2.20519716e-03  -1.63086888e-02\n",
      "   1.64501047e-03  -3.35123698e-01  -3.73533559e-03   8.63693798e-04\n",
      "   1.63181312e-03  -3.29711914e-01  -1.04553928e-02   1.46484375e-03]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "(8192, 32)\n",
      "[2 4 0 ..., 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "feat=train_df.values[:,:-2]\n",
    "\n",
    "#Normalize the features\n",
    "\n",
    "feat_max = np.amax(feat,axis=0)\n",
    "feat_min = np.amin(feat,axis=0)\n",
    "\n",
    "feat=(feat-feat_min)/(feat_max-feat_min)\n",
    "feat=feat*2-1\n",
    "\n",
    "'''feat_mean = np.mean(feat,axis=0)\n",
    "feat_std = np.std(feat,axis=0)\n",
    "\n",
    "feat=(feat-feat_mean)/feat_std\n",
    "'''\n",
    "label_ord=train_df.values[:,-1].astype(np.int)\n",
    "\n",
    "print(np.mean(feat,axis=0))\n",
    "print(np.min(feat,axis=0))\n",
    "print(feat.shape)\n",
    "print(label_ord)\n",
    "\n",
    "fvec=feat.copy()\n",
    "#label=np.eye(num_classes)[label_ord]\n",
    "#print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(7192,)\n",
      "(1000, 32)\n",
      "(7192, 32)\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "test_idx=sorted_idx[np.floor(np.linspace(0,len(label_ord)-1,test_size)).astype(np.int)]\n",
    "train_idx = np.setdiff1d(np.arange(0,len(label_ord)),test_idx)\n",
    "\n",
    "\n",
    "\n",
    "label_ord_test=label_ord[test_idx]\n",
    "label_ord_train=label_ord[train_idx]\n",
    "#label_test=np.eye(num_classes)[label_ord_test]\n",
    "#label_train=np.eye(num_classes)[label_ord_train]\n",
    "fvec_test=fvec[test_idx,:]\n",
    "fvec_train=fvec[train_idx,:]\n",
    "\n",
    "print(label_ord_test.shape)\n",
    "print(label_ord_train.shape)\n",
    "print(fvec_test.shape)\n",
    "print(fvec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -1.88317491e-02   1.64733924e-02  -1.00358358e-01  -7.12058869e-02\n",
      "  -1.01446282e-02   2.00886136e+00   7.72151419e-03   1.67966693e-03\n",
      "  -1.51213653e-01  -3.32255414e-01  -3.06772015e-03   3.00310220e+00\n",
      "  -1.85726251e-02   3.62893444e-02  -9.81725267e-02  -6.81625413e-02\n",
      "   1.99362178e-03   2.35966383e+00  -1.72680852e-01   2.79800411e-03\n",
      "  -9.64941303e-03   1.53275991e-01  -1.90156013e-01  -3.18897837e-02\n",
      "  -5.37415994e-02   2.62896193e-01  -2.63141216e-02  -1.45610755e-02\n",
      "   2.80541112e-02   3.04330277e-01   1.19621218e-02  -5.93394855e-01]\n",
      "Training\n",
      "Mean absolute error: 0.74\n",
      "Accuracy: 0.38\n",
      "Validation\n",
      "Mean absolute error: 0.72\n",
      "Accuracy: 0.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.Ridge(alpha = .5)\n",
    "\n",
    "# Train the model using training sets\n",
    "regr.fit(fvec_train, label_ord_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "label_ord_pred = np.round(regr.predict(fvec_test)).astype(np.int)\n",
    "label_ord_pred[label_ord_pred<0]=0\n",
    "label_ord_pred[label_ord_pred>=num_classes]=num_classes-1\n",
    "\n",
    "label_ord_tr_pred = np.round(regr.predict(fvec_train)).astype(np.int)\n",
    "label_ord_tr_pred[label_ord_tr_pred<0]=0\n",
    "label_ord_tr_pred[label_ord_tr_pred>=num_classes]=num_classes-1\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print('Training')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_tr_pred, label_ord_train))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_tr_pred==label_ord_train))\n",
    "\n",
    "# The mean squared error\n",
    "print('Validation')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_pred, label_ord_test))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_pred==label_ord_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([241,   0, 181,   0,   0, 221,   0, 174,   0, 183]), array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]))\n",
      "(array([203,   0, 199,   0,   0, 199,   0, 199,   0, 200]), array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]))\n",
      "Coefficients: \n",
      " [ -1.88317491e-02   1.64733924e-02  -1.00358358e-01  -7.12058869e-02\n",
      "  -1.01446282e-02   2.00886136e+00   7.72151419e-03   1.67966693e-03\n",
      "  -1.51213653e-01  -3.32255414e-01  -3.06772015e-03   3.00310220e+00\n",
      "  -1.85726251e-02   3.62893444e-02  -9.81725267e-02  -6.81625413e-02\n",
      "   1.99362178e-03   2.35966383e+00  -1.72680852e-01   2.79800411e-03\n",
      "  -9.64941303e-03   1.53275991e-01  -1.90156013e-01  -3.18897837e-02\n",
      "  -5.37415994e-02   2.62896193e-01  -2.63141216e-02  -1.45610755e-02\n",
      "   2.80541112e-02   3.04330277e-01   1.19621218e-02  -5.93394855e-01]\n",
      "Training\n",
      "Mean absolute error: 0.69\n",
      "Accuracy: 0.53\n",
      "Validation\n",
      "Mean absolute error: 0.79\n",
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "\n",
    "clf.fit(fvec_train, label_ord_train)\n",
    "label_ord_pred = clf.predict(fvec_test)\n",
    "label_ord_tr_pred = clf.predict(fvec_train)\n",
    "print(np.histogram(label_ord_pred))\n",
    "print(np.histogram(label_ord_test))\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "\n",
    "# The mean squared error\n",
    "print('Training')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_tr_pred, label_ord_train))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_tr_pred==label_ord_train))\n",
    "\n",
    "# The mean squared error\n",
    "print('Validation')\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(label_ord_pred, label_ord_test))\n",
    "\n",
    "#CCR \n",
    "print(\"Accuracy: %.2f\"\n",
    "      % np.mean(label_ord_pred==label_ord_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "label_test=np.eye(num_classes)[label_ord_test]\n",
    "label_train=np.eye(num_classes)[label_ord_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp(x, hidden_sizes, activation_fn=tf.nn.relu,dropout_rate=.5,std_dev=1.0):\n",
    "    if not isinstance(hidden_sizes, (list, tuple)):\n",
    "        raise ValueError(\"hidden_sizes must be a list or a tuple\")\n",
    "        \n",
    "    scope_args = {'initializer': tf.random_normal_initializer(stddev=std_dev)}\n",
    "    \n",
    "    for k in range(len(hidden_sizes)-1):\n",
    "        layer_name=\"weights\"+str(k)\n",
    "        #FC layers\n",
    "        with tf.variable_scope(layer_name, **scope_args):\n",
    "            W = tf.get_variable('W', shape=[x.shape[-1], hidden_sizes[k]])\n",
    "            b = tf.get_variable('b', shape=[hidden_sizes[k]])\n",
    "            x = activation_fn(tf.matmul(x, W) + b)\n",
    "            #Dropout before the last layer\n",
    "            x = tf.nn.dropout(x, keep_prob=dropout_rate)\n",
    "    #Softmax layer\n",
    "    with tf.variable_scope('outlayer', **scope_args):\n",
    "        W = tf.get_variable('W', shape=[x.shape[-1], hidden_sizes[-1]])\n",
    "        b = tf.get_variable('b', shape=[hidden_sizes[-1]])\n",
    "        return tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''fvec_n=fvec/np.round(np.max(label))\n",
    "label_n = label/np.round(np.max(label))'''\n",
    "def test_classification(model_function, learning_rate=0.1,num_iter=30000,num_log=2000):\n",
    "\n",
    "    with tf.Graph().as_default() as g:\n",
    "        # where are you going to allocate memory and perform computations\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            \n",
    "            # define model \"input placeholders\", i.e. variables that are\n",
    "            # going to be substituted with input data on train/test time\n",
    "            x_ = tf.placeholder(tf.float32, [None, fvec.shape[1]])\n",
    "            y_ = tf.placeholder(tf.float32, [None, num_classes])\n",
    "            y_logits = model_function(x_)\n",
    "            \n",
    "\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_logits))\n",
    "            '''train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)'''\n",
    "            train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "           \n",
    "            y_pred = tf.argmax(y_logits, 1)\n",
    "            y_true = tf.argmax(y_,1)\n",
    "            correct_prediction = tf.equal(y_pred, y_true)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            mae_error = tf.reduce_mean(tf.cast(tf.abs(y_pred-y_true), tf.float32))\n",
    "\n",
    "    with g.as_default(), tf.Session() as sess:\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # train\n",
    "        ids=[i for i in range(128)]\n",
    "        for iter_i in range(num_iter+1):\n",
    "            batch_xs = fvec_train[ids,:] \n",
    "            batch_ys = label_train[ids]\n",
    "            ids=[(ids[0]+100+i)%label_train.shape[0] for i in range(100)]\n",
    "            sess.run(train_step, feed_dict={x_: batch_xs, y_: batch_ys})\n",
    "            \n",
    "            # test trained model\n",
    "            if iter_i % num_log == 0:\n",
    "                tf_feed_dict = {x_: fvec_train, y_: label_train}\n",
    "                loss_tr, acc_tr, mae_tr, y_pred_tr,y_true_tr= sess.run(\n",
    "                    [loss, accuracy, mae_error, y_pred,y_true], feed_dict=tf_feed_dict)\n",
    "                tf_feed_dict = {x_: fvec_test, y_: label_test}\n",
    "                loss_val, acc_val, mae_val, y_pred_val,y_true_val= sess.run(\n",
    "                    [loss, accuracy, mae_error, y_pred,y_true], feed_dict=tf_feed_dict)\n",
    "                print('iteration %d\\t Training: loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t, Validation: loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t'%\n",
    "                      (iter_i, loss_tr, mae_tr, acc_tr, loss_val, mae_val, acc_val))\n",
    "                '''loss_val= sess.run(loss, feed_dict=tf_feed_dict)\n",
    "                print('iteration %d\\t loss: %.5f\\t MAE: %.5f\\t acc: %.5f\\t'%\n",
    "                      (iter_i, loss_val, loss_val, loss_val))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\t Training: loss: 1.61273\t MAE: 1.35623\t acc: 0.19702\t, Validation: loss: 1.61241\t MAE: 1.35700\t acc: 0.19200\t\n",
      "iteration 2000\t Training: loss: 1.47498\t MAE: 1.13140\t acc: 0.35053\t, Validation: loss: 1.44077\t MAE: 1.10400\t acc: 0.36000\t\n",
      "iteration 4000\t Training: loss: 1.42999\t MAE: 1.10428\t acc: 0.35428\t, Validation: loss: 1.45174\t MAE: 1.10300\t acc: 0.35800\t\n",
      "iteration 6000\t Training: loss: 1.40367\t MAE: 0.99486\t acc: 0.37625\t, Validation: loss: 1.37136\t MAE: 0.93600\t acc: 0.40500\t\n",
      "iteration 8000\t Training: loss: 1.38688\t MAE: 0.99819\t acc: 0.38181\t, Validation: loss: 1.45761\t MAE: 0.96700\t acc: 0.39100\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e2b1cd43df2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m test_classification(\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_dev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     learning_rate=1e-3,num_iter=100000,num_log=2000)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-39ff4550697f>\u001b[0m in \u001b[0;36mtest_classification\u001b[0;34m(model_function, learning_rate, num_iter, num_log)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlabel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# test trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozan-macbook-air/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozan-macbook-air/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;31m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;31m# of a handle from a different device as an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m     \u001b[0mfinal_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mfinal_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozan-macbook-air/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_update_with_movers\u001b[0;34m(self, feed_dict, feed_map)\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0mhandle_movers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeed_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m       \u001b[0mmover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handle_mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mhandle_movers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 16, 12, 12, 8, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=100000,num_log=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=500000,num_log=10000)\n",
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-4,num_iter=500000,num_log=10000)\n",
    "test_classification(\n",
    "    lambda x: mlp(x, [32, 16, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=500000,num_log=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=1e-3,num_iter=1000000,num_log=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classification(\n",
    "    lambda x: mlp(x, [16, 12, 8, 5], activation_fn=tf.nn.relu,std_dev=.1), \n",
    "    learning_rate=5e-4,num_iter=300000,num_log=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
